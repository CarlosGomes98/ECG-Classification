{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.decomposition as decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, auc, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PTBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../data/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"../data/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings from baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11641, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(\"../baseline/baseline_cnn_ptbdb.h5\")\n",
    "embedding_model = Model(inputs=model.inputs, outputs=model.layers[15].output) # get embeddings from last conv layer\n",
    "\n",
    "embeddings = embedding_model.predict(X)\n",
    "embeddings_test = embedding_model.predict(X_test)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(embeddings, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9950225171841669 \n",
      "Test accuracy score : 0.9927859841978701 \n",
      "AUROC score : 0.9927859841978701 \n",
      "AUPRC score : 0.9955503817455404 \n",
      "[[ 791   18]\n",
      " [   3 2099]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = svm.predict(embeddings_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "auc_roc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"AUROC score : %s \"% acc)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_test, pred_test)\n",
    "\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUPRC score : %s \"% auc_prc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try applying pca to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_normalized = embeddings - embeddings.mean(axis=0)\n",
    "embeddings_test_normalized = embeddings_test - embeddings_test.mean(axis=0)\n",
    "pca = decomposition.PCA(n_components=64)\n",
    "components = pca.fit_transform(embeddings_normalized)\n",
    "components_test = pca.transform(embeddings_test_normalized)\n",
    "svm_pca = SVC()\n",
    "svm_pca.fit(components, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9945432977461446 \n",
      "Test accuracy score : 0.9920989350738578 \n",
      "AUROC score : 0.9920989350738578 \n",
      "AUPRC score : 0.9955806449903406 \n",
      "[[ 792   17]\n",
      " [   6 2096]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = svm_pca.predict(components_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "auc_roc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"AUROC score : %s \"% acc)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_test, pred_test)\n",
    "\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUPRC score : %s \"% auc_prc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(n_jobs=-1)\n",
    "clf.fit(embeddings, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.993361782835467 \n",
      "Test accuracy score : 0.9903813122638269 \n",
      "AUROC score : 0.9903813122638269 \n",
      "AUPRC score : 0.9945750622750296 \n",
      "[[ 788   21]\n",
      " [   7 2095]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = clf.predict(embeddings_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "auc_roc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"AUROC score : %s \"% acc)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_test, pred_test)\n",
    "\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUPRC score : %s \"% auc_prc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pca = XGBClassifier(n_jobs=-1)\n",
    "clf_pca.fit(components, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9886148007590133 \n",
      "Test accuracy score : 0.9835108210237032 \n",
      "AUROC score : 0.9835108210237032 \n",
      "AUPRC score : 0.9917145310682545 \n",
      "[[ 779   30]\n",
      " [  18 2084]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = clf_pca.predict(components_test)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "auc_roc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"AUROC score : %s \"% acc)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_test, pred_test)\n",
    "\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUPRC score : %s \"% auc_prc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
