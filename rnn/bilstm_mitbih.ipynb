{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "This model is a network with 3 reccurent layers followed by a fully connected layer. We found the GRUs worked better than LSTMs, besides resulting in faster train times. We arrived at these parameters through [hyperparameter-tuning](hyperparameter-tuning_mitbih.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Network](rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GRU, \\\n",
    "    concatenate, Add, Activation\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"../data/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and skip to [evaluation](#evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "model = load_model(\"rnn_mitbih.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plot_model(model, to_file=\"rnn.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or ALTERNATIVELY train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 187\n",
    "\n",
    "def get_model():\n",
    "    n_class = 5\n",
    "    inp = Input(shape=(187, 1))\n",
    "    x = GRU(128,\n",
    "           return_sequences=True,\n",
    "           dropout=0.2)(inp)\n",
    "    x = GRU(128,\n",
    "           return_sequences=True,\n",
    "           dropout=0.2)(x)\n",
    "    x = GRU(128,\n",
    "           return_sequences=False,\n",
    "           dropout=0.2)(x)\n",
    "    \n",
    "    dense = Dense(64, activation='relu')(x)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    output = Dense(n_class, activation='softmax')(dense)\n",
    "    \n",
    "    opt = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=output)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    model = get_model()\n",
    "    file_path = \"rnn_mitbih_retrain.h5\"\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "    redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "    callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "    model.fit(X, Y, epochs=1000, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
    "    model.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "<a id='evaluate'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9028542162135643 \n",
      "Test accuracy score : 0.9835099579755162 \n",
      "[[18027    58    15     7    11]\n",
      " [  118   423    13     0     2]\n",
      " [   40     4  1370    23    11]\n",
      " [   27     0    16   119     0]\n",
      " [   14     0     2     0  1592]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
