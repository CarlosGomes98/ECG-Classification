{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import optimizers, losses, activations, models, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GRU, \\\n",
    "    concatenate, Add, Activation\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"data/ptbdb_normal.csv\", header=None)\n",
    "df_2 = pd.read_csv(\"data/ptbdb_abnormal.csv\", header=None)\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "full_model = load_model('rnn_transfer.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or ALTERNATIVELY train it\n",
    "#### Please skip to Evaluate if you don't want to retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = load_model(\"rnn/rnn_mitbih.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove dense layers and freeze remaining layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_model = Model(model.input, model.layers[3].output)\n",
    "for i in range(3):\n",
    "    cropped_model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_input (InputLayer)       [(None, 187, 1)]          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 187, 128)          50304     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 187, 128)          99072     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               99072     \n",
      "=================================================================\n",
      "Total params: 248,448\n",
      "Trainable params: 0\n",
      "Non-trainable params: 248,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cropped_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 187\n",
    "\n",
    "def get_model():\n",
    "    n_class = 1\n",
    "    \n",
    "    x = cropped_model.output\n",
    "    dense = Dense(64, activation='relu')(x)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    output = Dense(n_class, activation='sigmoid')(dense)\n",
    "    \n",
    "    opt = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    full_model = models.Model(inputs=cropped_model.input, outputs=output)\n",
    "    class_weights = compute_class_weight('balanced', [0, 1], Y)\n",
    "\n",
    "    full_model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    full_model.summary()\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = get_model()\n",
    "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [early, redonplat]  # early\n",
    "\n",
    "full_model.fit(X, Y, epochs=1000, verbose=1, callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfreeze layers and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    full_model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"rnn_transfer_retrain.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "full_model.fit(X, Y, epochs=1000, verbose=1, callbacks=callbacks_list, validation_split=0.1)\n",
    "full_model.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9089676982154958 \n",
      "Test accuracy score : 0.8615596015115081 \n",
      "AUROC score : 0.7851431152154814 \n",
      "AUPRC score : 0.92673859465013 \n",
      "[[ 496  313]\n",
      " [  90 2012]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = full_model.predict(X_test)\n",
    "pred_test = (pred_test>0.5).astype(np.int8)\n",
    "\n",
    "f1 = f1_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test f1 score : %s \"% f1)\n",
    "\n",
    "acc = accuracy_score(Y_test, pred_test)\n",
    "\n",
    "print(\"Test accuracy score : %s \"% acc)\n",
    "\n",
    "auc_roc = roc_auc_score(Y_test, pred_test)\n",
    "\n",
    "print(\"AUROC score : %s \"% auc_roc)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_test, pred_test)\n",
    "\n",
    "auc_prc = auc(recall, precision)\n",
    "print(\"AUPRC score : %s \"% auc_prc)\n",
    "\n",
    "print(confusion_matrix(Y_test, pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ECG] *",
   "language": "python",
   "name": "conda-env-ECG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
