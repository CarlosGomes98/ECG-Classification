{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.decomposition as decomposition\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87554, 187, 1), (87554,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"data/mitbih_test.csv\", header=None)\n",
    "\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n",
    "\n",
    "n_class = np.unique(Y).size\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 187\n",
    "\n",
    "def get_model():\n",
    "    n_class = 5\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, \n",
    "                   input_shape=(seq_len, 1), \n",
    "                   activation='relu', \n",
    "                   return_sequences=True,\n",
    "                   dropout=0.2))\n",
    "    model.add(LSTM(128, \n",
    "                   activation='relu',\n",
    "                   return_sequences=False, \n",
    "                   dropout=0.1))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_simple_model():\n",
    "    n_class = 5\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, \n",
    "                   input_shape=(seq_len, 1), \n",
    "                   activation='relu', \n",
    "                   return_sequences=False,\n",
    "                   dropout=0.2))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_class, activation='softmax'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "    \n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 187, 128)          66560     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 202,437\n",
      "Trainable params: 202,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int8),\n",
       " array([815,  32,  68,  10,  75], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_X = X[:1000, :, :]\n",
    "mini_Y = Y[:1000]\n",
    "\n",
    "np.unique(mini_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/10\n",
      "78798/78798 [==============================] - 802s 10ms/sample - loss: 9359519107187246.0000 - accuracy: 0.8276 - val_loss: 0.6797 - val_accuracy: 0.8278\n",
      "Epoch 2/10\n",
      "78798/78798 [==============================] - 785s 10ms/sample - loss: 0.6658 - accuracy: 0.8277 - val_loss: 0.6575 - val_accuracy: 0.8278\n",
      "Epoch 3/10\n",
      "18048/78798 [=====>........................] - ETA: 12:40 - loss: 0.6620 - accuracy: 0.8261"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", \"scalars\", str(datetime.now().strftime('%Y%m%d-%H%M%S')))\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(X[:, :, :], Y[:], \n",
    "          epochs=10, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(mini_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
